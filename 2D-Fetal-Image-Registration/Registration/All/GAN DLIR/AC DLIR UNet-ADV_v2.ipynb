{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58654a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import set_determinism, first\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirstD,\n",
    "    Compose,\n",
    "    LoadImageD,\n",
    "    RandRotateD,\n",
    "    RandZoomD,\n",
    "    ScaleIntensityRanged,\n",
    ")\n",
    "import monai\n",
    "from monai.data import DataLoader, Dataset, CacheDataset\n",
    "from monai.config import print_config, USE_COMPILED\n",
    "from monai.networks.nets import GlobalNet, LocalNet, RegUNet\n",
    "from monai.networks.blocks import Warp\n",
    "from monai.apps import MedNISTDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from glob import glob\n",
    "import cv2\n",
    "import torchmetrics\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tempfile\n",
    "from monai.losses import *\n",
    "from monai.metrics import *\n",
    "from piqa import SSIM\n",
    "\n",
    "\n",
    "print_config()\n",
    "set_determinism(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8094c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = 'CAMUS_EStoED_A2C'\n",
    "\n",
    "root_dir = 'data/'+dataDir+'/'\n",
    "print(root_dir)\n",
    "\n",
    "fileNames = \"adv_AC_DLIR_UNet\" + dataDir\n",
    "\n",
    "trainBatch = 8\n",
    "testBatch = 8\n",
    "\n",
    "img_size = 256\n",
    "\n",
    "EP = 200\n",
    "\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a80dee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('How many GPUs = ' + str(torch.cuda.device_count()))\n",
    "\n",
    "#checking for device\n",
    "\n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "  raise Exception(\"GPU not availalbe. CPU training will be too slow.\")\n",
    "\n",
    "print(\"device name\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EchoDataset(Dataset):\n",
    "    def __init__(self, images_path):\n",
    "\n",
    "        self.images_path = images_path\n",
    "        self.n_samples = len(images_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Reading image \"\"\"\n",
    "        image = cv2.imread(self.images_path[index], cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image,(img_size, img_size))\n",
    "        image = image/(image.max()) ## (512, 512, 3)\n",
    "#         print(image.max())\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image.astype(np.float32)\n",
    "        self.images_path[index]\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "class EchoDatasetMask(Dataset):\n",
    "    def __init__(self, images_path):\n",
    "\n",
    "        self.images_path = images_path\n",
    "        self.n_samples = len(images_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Reading image \"\"\"\n",
    "        image = cv2.imread(self.images_path[index], cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image,(img_size, img_size), interpolation=cv2.INTER_NEAREST)\n",
    "#         print(image.max())\n",
    "#         image = image/(image.max()) ## (512, 512, 3)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        image = image.astype(np.float32)\n",
    "        self.images_path[index]\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188808c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(train_dir,\n",
    "                batch_size,\n",
    "                num_workers,\n",
    "                pin_memory):\n",
    "    \n",
    "    train_data = EchoDataset(images_path=train_dir)\n",
    "\n",
    "    train_loader = DataLoader(train_data,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers,\n",
    "                              pin_memory=pin_memory,\n",
    "                              shuffle=False)\n",
    "\n",
    "    return train_loader\n",
    "\n",
    "def get_batches_mask(train_dir,\n",
    "                batch_size,\n",
    "                num_workers,\n",
    "                pin_memory):\n",
    "    \n",
    "    train_data = EchoDatasetMask(images_path=train_dir)\n",
    "\n",
    "    train_loader = DataLoader(train_data,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers,\n",
    "                              pin_memory=pin_memory,\n",
    "                              shuffle=False)\n",
    "\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "print(f'Train Sample numbers (fixed_img) = {len(sorted(glob(root_dir+\"/train/fixed_img/*.png\")))}')\n",
    "print(f'Train Sample numbers (fixed_msk) = {len(sorted(glob(root_dir+\"/train/fixed_msk/*.png\")))}')\n",
    "print(f'Train Sample numbers (moving_img) = {len(sorted(glob(root_dir+\"/train/moving_img/*.png\")))}')\n",
    "print(f'Train Sample numbers (moving_msk) = {len(sorted(glob(root_dir+\"/train/moving_msk/*.png\")))}')\n",
    "print()\n",
    "print(f'Val Sample numbers (fixed_img) = {len(sorted(glob(root_dir+\"/val/fixed_img/*.png\")))}')\n",
    "print(f'Val Sample numbers (fixed_msk) = {len(sorted(glob(root_dir+\"/val/fixed_msk/*.png\")))}')\n",
    "print(f'Val Sample numbers (moving_img) = {len(sorted(glob(root_dir+\"/val/moving_img/*.png\")))}')\n",
    "print(f'Val Sample numbers (moving_msk) = {len(sorted(glob(root_dir+\"/val/moving_msk/*.png\")))}')\n",
    "print()\n",
    "\n",
    "\n",
    "fixed_train_img = get_batches(train_dir = sorted(glob(root_dir+\"/train/fixed_img/*\")),\n",
    "                                        batch_size = trainBatch,\n",
    "                                        num_workers = num_workers,\n",
    "                                        pin_memory = True)\n",
    "\n",
    "fixed_train_msk = get_batches_mask(train_dir = sorted(glob(root_dir+\"/train/fixed_msk/*\")),\n",
    "                                        batch_size = trainBatch,\n",
    "                                        num_workers = num_workers,\n",
    "                                        pin_memory = True)\n",
    "\n",
    "\n",
    "moving_train_img = get_batches(train_dir = sorted(glob(root_dir+\"/train/moving_img/*\")),\n",
    "                                        batch_size = trainBatch,\n",
    "                                        num_workers = num_workers,\n",
    "                                        pin_memory = True)\n",
    "\n",
    "moving_train_msk = get_batches_mask(train_dir = sorted(glob(root_dir+\"/train/moving_msk/*\")),\n",
    "                                        batch_size = trainBatch,\n",
    "                                        num_workers = num_workers,\n",
    "                                        pin_memory = True)\n",
    "\n",
    "\n",
    "print(\"Train IMG FIXED:\", fixed_train_img)\n",
    "print(\"Train MSK FIXED:\", fixed_train_msk)\n",
    "print(\"Train IMG Moving:\", moving_train_img)\n",
    "print(\"Train MSK Moving:\", moving_train_msk)\n",
    "\n",
    "\n",
    "fixed_val_img = get_batches(train_dir = sorted(glob(root_dir+\"/val/fixed_img/*\")),\n",
    "                                        batch_size = testBatch,\n",
    "                                        num_workers = num_workers,\n",
    "                                        pin_memory = True)\n",
    "\n",
    "fixed_val_msk = get_batches_mask(train_dir = sorted(glob(root_dir+\"/val/fixed_msk/*\")),\n",
    "                                        batch_size = testBatch,\n",
    "                                        num_workers = num_workers,\n",
    "                                        pin_memory = True)\n",
    "\n",
    "\n",
    "moving_val_img = get_batches(train_dir = sorted(glob(root_dir+\"/val/moving_img/*\")),\n",
    "                                        batch_size = testBatch,\n",
    "                                        num_workers = num_workers,\n",
    "                                        pin_memory = True)\n",
    "\n",
    "moving_val_msk = get_batches_mask(train_dir = sorted(glob(root_dir+\"/val/moving_msk/*\")),\n",
    "                                        batch_size = testBatch,\n",
    "                                        num_workers = num_workers,\n",
    "                                        pin_memory = True)\n",
    "\n",
    "\n",
    "print(\"Val IMG FIXED:\", fixed_val_img)\n",
    "print(\"Val MSK FIXED:\", fixed_val_msk)\n",
    "print(\"Val IMG Moving:\", moving_val_img)\n",
    "print(\"Val MSK Moving:\", moving_val_msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "      'fixed_train_img': fixed_train_img,\n",
    "      'fixed_train_msk': fixed_train_msk,\n",
    "    'moving_train_img': moving_train_img,\n",
    "    'moving_train_msk': moving_train_msk,\n",
    "    'fixed_val_img': fixed_val_img,\n",
    "    'fixed_val_msk': fixed_val_msk,\n",
    "    'moving_val_img': moving_val_img,\n",
    "    'moving_val_msk': moving_val_msk\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1e5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_train_img_ = first(dataloaders[\"fixed_train_img\"])[0][0]\n",
    "fixed_train_msk_ = first(dataloaders[\"fixed_train_msk\"])[0][0]\n",
    "moving_train_img_ = first(dataloaders[\"moving_train_img\"])[0][0]\n",
    "moving_train_msk_ = first(dataloaders[\"moving_train_msk\"])[0][0]\n",
    "\n",
    "fixed_val_img_ = first(dataloaders[\"fixed_val_img\"])[0][0]\n",
    "fixed_val_msk_ = first(dataloaders[\"fixed_val_msk\"])[0][0]\n",
    "moving_val_img_ = first(dataloaders[\"moving_val_img\"])[0][0]\n",
    "moving_val_msk_ = first(dataloaders[\"moving_val_msk\"])[0][0]\n",
    "\n",
    "\n",
    "print(f\"fixed_train_img_ shape: {fixed_train_img_.shape}\")\n",
    "print(f\"fixed_train_msk_ shape: {fixed_train_msk_.shape}\")\n",
    "print(f\"moving_train_img_ shape: {moving_train_img_.shape}\")\n",
    "print(f\"moving_train_msk_ shape: {moving_train_msk_.shape}\")\n",
    "\n",
    "print(f\"fixed_val_img_ shape: {fixed_val_img_.shape}\")\n",
    "print(f\"fixed_val_msk_ shape: {fixed_val_msk_.shape}\")\n",
    "print(f\"moving_val_img_ shape: {moving_val_img_.shape}\")\n",
    "print(f\"moving_val_msk_ shape: {moving_val_msk_.shape}\")\n",
    "\n",
    "\n",
    "print(f\"fixed_train_img_ Range: {fixed_train_img_.max()} {fixed_train_img_.min()}\")\n",
    "print(f\"fixed_train_msk_ range: {fixed_train_msk_.max()} {fixed_train_msk_.min()} {np.unique(fixed_train_msk_)}\")\n",
    "print(f\"moving_train_img_ Range: {moving_train_img_.max()} {moving_train_img_.min()}\")\n",
    "print(f\"moving_train_msk_ range: {moving_train_msk_.max()} {moving_train_msk_.min()} {np.unique(moving_train_msk_)}\")\n",
    "\n",
    "print(f\"fixed_val_img_ Range: {fixed_val_img_.max()} {fixed_val_img_.min()}\")\n",
    "print(f\"fixed_val_msk_ range: {fixed_val_msk_.max()} {fixed_val_msk_.min()} {np.unique(fixed_val_msk_)}\")\n",
    "print(f\"moving_val_img_ Range: {moving_val_img_.max()} {moving_val_img_.min()}\")\n",
    "print(f\"moving_val_msk_ range: {moving_val_msk_.max()} {moving_val_msk_.min()} {np.unique(moving_val_msk_)}\")\n",
    "\n",
    "\n",
    "plt.figure(\"check\", (10, 5))\n",
    "\n",
    "plt.subplot(2, 4, 1)\n",
    "plt.title(\"fixed_train_img_\")\n",
    "plt.imshow(fixed_train_img_, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 2)\n",
    "plt.title(\"fixed_train_msk_\")\n",
    "plt.imshow(fixed_train_msk_, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 3)\n",
    "plt.title(\"moving_train_img_\")\n",
    "plt.imshow(moving_train_img_, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 4)\n",
    "plt.title(\"moving_train_msk_\")\n",
    "plt.imshow(moving_train_msk_, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.subplot(2, 4, 5)\n",
    "plt.title(\"fixed_val_img_\")\n",
    "plt.imshow(fixed_val_img_, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 6)\n",
    "plt.title(\"fixed_val_msk_\")\n",
    "plt.imshow(fixed_val_msk_, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 7)\n",
    "plt.title(\"moving_val_img_\")\n",
    "plt.imshow(moving_val_img_, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 4, 8)\n",
    "plt.title(\"moving_val_msk_\")\n",
    "plt.imshow(moving_val_msk_, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2773c62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = RegUNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=2,\n",
    "    num_channel_initial=32,\n",
    "    depth = 5,\n",
    "    extract_levels=[5],\n",
    "    out_activation=None,\n",
    "    out_channels=2,\n",
    "    out_kernel_initializer=\"zeros\",\n",
    "    concat_skip=False)\n",
    "\n",
    "        \n",
    "\n",
    "inputs = torch.randn((2, 2, img_size, img_size))\n",
    "\n",
    "y = mod(inputs)\n",
    "print(y.shape)\n",
    "\n",
    "import torch, torchinfo\n",
    "# from torchviz import make_dot, make_dot_from_trace\n",
    "    \n",
    "# make_dot(y, params=dict(mod.named_parameters()),\n",
    "#          show_attrs=False,\n",
    "#          show_saved=False).render(fileNames, format=\"png\")\n",
    "\n",
    "torchinfo.summary(mod, input_size=(2, 2, img_size, img_size), depth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c0b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mod.to(device)\n",
    "\n",
    "\n",
    "warp_layer = Warp().to(device)\n",
    "\n",
    "# image_loss = MSELoss()\n",
    "\n",
    "image_loss = GlobalMutualInformationLoss()\n",
    "\n",
    "class SSIMLoss(SSIM):\n",
    "    def forward(self, x, y):\n",
    "        return 1. - super().forward(x, y)\n",
    "    \n",
    "\n",
    "label_SSIM = SSIMLoss(n_channels=1).to(device) # .cuda() if you need GPU support\n",
    "\n",
    "label_loss = DiceLoss()\n",
    "\n",
    "# label_loss = MultiScaleLoss(label_loss, scales=[0, 1, 2, 4, 8, 16])\n",
    "\n",
    "regularization = BendingEnergyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.0002)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "\n",
    "\n",
    "# dice_metric = compute_meandice(y_pred, y, include_background=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225f00ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_hot(labels, C=2):\n",
    "    '''\n",
    "    Converts an integer label torch.autograd.Variable to a one-hot Variable.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : torch.autograd.Variable of torch.cuda.LongTensor\n",
    "        N x 1 x H x W, where N is batch size. \n",
    "        Each value is an integer representing correct classification.\n",
    "    C : integer. \n",
    "        number of classes in labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    target : torch.autograd.Variable of torch.cuda.FloatTensor\n",
    "        N x C x H x W, where C is class number. One-hot encoded.\n",
    "    '''\n",
    "    labels = labels.long()\n",
    "    one_hot = torch.FloatTensor(labels.size(0), C, labels.size(2), labels.size(3)).zero_().to(device)\n",
    "    target = one_hot.scatter_(1, labels.data, 1)\n",
    "    \n",
    "    target = Variable(target)\n",
    "        \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814874b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalEncoder(nn.Module):\n",
    "    def __init__(self, latent_dims):  \n",
    "        super(VariationalEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, stride=2, padding=1)\n",
    "        self.batch2 = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 3, stride=2, padding=1)  \n",
    "        self.linear1 = nn.Linear(img_size//8*img_size//8*32, 128)\n",
    "        self.linear2 = nn.Linear(128, latent_dims)\n",
    "        self.linear3 = nn.Linear(128, latent_dims)\n",
    "\n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "        self.N.loc = self.N.loc.to(device) # hack to get sampling on the GPU\n",
    "        self.N.scale = self.N.scale.to(device)\n",
    "        self.kl = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.batch2(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        # print(f'XX = {x.shape}')\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        # print(f'XX = {x.shape}')\n",
    "        x = F.relu(self.linear1(x))\n",
    "        mu =  self.linear2(x)\n",
    "        sigma = torch.exp(self.linear3(x))\n",
    "        z = mu + sigma*self.N.sample(mu.shape)\n",
    "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n",
    "        return z      \n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dims):\n",
    "        super().__init__()\n",
    "\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            nn.Linear(latent_dims, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, img_size//8*img_size//8*32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, img_size//8, img_size//8))\n",
    "        \n",
    "        self.m = nn.Softmax(dim=1)\n",
    "\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder_lin(x)\n",
    "        x = self.unflatten(x)\n",
    "        x = self.decoder_conv(x)\n",
    "        x = torch.sigmoid(x)\n",
    "#         x = self.m(x)\n",
    "        return x\n",
    "\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dims):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        self.encoder = VariationalEncoder(latent_dims)\n",
    "        self.decoder = Decoder(latent_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        z = self.encoder(x)\n",
    "#         print(f'Latent dim = {z.shape}')\n",
    "#         print(f'Latent Value = {z}')\n",
    "        return self.decoder(z)\n",
    "\n",
    "### Set the random seed for reproducible results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "d = 8\n",
    "\n",
    "Myo_VAE = VariationalAutoencoder(latent_dims=d)\n",
    "Myo_VAE.to(device)\n",
    "Myo_VAE.load_state_dict(torch.load('ACVAE Weights/'+'Myo_VAE_'+ str(img_size) + '_.pth', map_location= device))\n",
    "Myo_VAE.eval()\n",
    "\n",
    "# torchinfo.summary(Myo_VAE, input_size=(2, 1, 512, 512), depth=100)\n",
    "\n",
    "LV_VAE = VariationalAutoencoder(latent_dims=d)\n",
    "LV_VAE.to(device)\n",
    "LV_VAE.load_state_dict(torch.load('ACVAE Weights/'+'LV_VAE_'+ str(img_size) + '_.pth', map_location= device))\n",
    "LV_VAE.eval()\n",
    "\n",
    "# torchinfo.summary(LV_VAE, input_size=(2, 1, 512, 512), depth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286cd90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_loss = nn.MSELoss(reduction='mean')\n",
    "\n",
    "def globalLoss(trueMask, predMask):\n",
    "    myo_trueMask = trueMask.clone()\n",
    "    LV_trueMask = trueMask.clone()\n",
    "\n",
    "    #Thresholding the prediction\n",
    "    thresholded_predMask = predMask.clone()\n",
    "\n",
    "    background_class = torch.zeros_like(predMask)\n",
    "    myo_class = torch.ones_like(predMask)\n",
    "    lv_class = 2*torch.ones_like(predMask)\n",
    "\n",
    "    thresholded_predMask_ = torch.where(thresholded_predMask<0.98, background_class, thresholded_predMask)\n",
    "    thresholded_predMask_ = torch.where(thresholded_predMask_>1.0, lv_class, thresholded_predMask_)\n",
    "    thresholded_predMask_ = torch.where((thresholded_predMask_<=1.0) & (thresholded_predMask_>=0.98), myo_class, thresholded_predMask_)\n",
    "\n",
    "    myo_predMask = thresholded_predMask_.clone()\n",
    "    LV_predMask = thresholded_predMask_.clone()\n",
    "\n",
    "    myo_predMask[myo_predMask==2] =0 \n",
    "    myo_trueMask[myo_trueMask==2] =0 \n",
    "\n",
    "    LV_predMask[LV_predMask==1] =0 \n",
    "    LV_predMask = LV_predMask/2\n",
    "\n",
    "    LV_trueMask[LV_trueMask==1] =0 \n",
    "    LV_trueMask = LV_trueMask/2\n",
    "\n",
    "    # plt.subplot(241), plt.imshow(myo_predMask[0,:,:,:].reshape(512,512).detach().cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "    # plt.subplot(242), plt.imshow(myo_trueMask[0,:,:,:].reshape(512,512).detach().cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "    # plt.subplot(243), plt.imshow(LV_predMask[0,:,:,:].reshape(512,512).detach().cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "    # plt.subplot(244), plt.imshow(LV_trueMask[0,:,:,:].reshape(512,512).detach().cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "\n",
    "    attribute_myo_true = Myo_VAE(myo_trueMask)\n",
    "    attribute_myo_pred = Myo_VAE(myo_predMask)\n",
    "\n",
    "    myo_L2 = L2_loss(attribute_myo_true, attribute_myo_pred)\n",
    "\n",
    "    attribute_lv_true = LV_VAE(LV_trueMask)\n",
    "    attribute_lv_pred = LV_VAE(LV_predMask)\n",
    "\n",
    "    # print(LV_trueMask.shape)\n",
    "    # print(attribute_lv_true.shape)\n",
    "\n",
    "    lv_L2 = L2_loss(attribute_lv_true, attribute_lv_pred)\n",
    "\n",
    "    # print(myo_L2)\n",
    "    # print(lv_L2)\n",
    "\n",
    "    loss_ = myo_L2 + lv_L2\n",
    "\n",
    "    return loss_\n",
    "\n",
    "# globalLoss (TTg, TTp)\n",
    "# globalLoss (TTg, TTm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d1bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create real labels (1s)\n",
    "def label_real(size):\n",
    "    data = torch.ones(size, 1)\n",
    "    return data.to(device)\n",
    "# to create fake labels (0s)\n",
    "def label_fake(size):\n",
    "    data = torch.zeros(size, 1)\n",
    "    return data.to(device)\n",
    "\n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Discriminator, self).__init__()\n",
    "#         self.n_input = 262144\n",
    "#         self.main = nn.Sequential(\n",
    "#             nn.Linear(self.n_input, 1024),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.3),\n",
    "\n",
    "#             # nn.Linear(4096, 2048),\n",
    "#             # nn.LeakyReLU(0.2),\n",
    "#             # nn.Dropout(0.3),\n",
    "\n",
    "#             # nn.Linear(1024, 1024),\n",
    "#             # nn.LeakyReLU(0.2),\n",
    "#             # nn.Dropout(0.3),\n",
    "\n",
    "#             nn.Linear(1024, 512),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.4),\n",
    "\n",
    "#             nn.Linear(512, 256),\n",
    "#             nn.LeakyReLU(0.2),\n",
    "#             nn.Dropout(0.4),\n",
    "\n",
    "#             nn.Linear(256, 1),\n",
    "#             # nn.Linear(64, 1),\n",
    "#             nn.Dropout(0.4),\n",
    "#             nn.Sigmoid(),\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(-1, 262144)\n",
    "#         return self.main(x)\n",
    "\n",
    "# Discriminator Model Class Definition\n",
    "# class Discriminator(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Discriminator, self).__init__()\n",
    "#         self.main = nn.Sequential(\n",
    "#             # Block 1: input is (3) x 64 x 64\n",
    "#             nn.Conv2d(1, 64, 4, 2, 1, bias=False),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # Block 2: input is (64) x 32 x 32\n",
    "#             nn.Conv2d(64, 64 * 2, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(64 * 2),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # Block 3: input is (64*2) x 16 x 16\n",
    "#             nn.Conv2d(64 * 2, 64 * 4, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(64 * 4),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # Block 4: input is (64*4) x 8 x 8\n",
    "#             nn.Conv2d(64 * 4, 64 * 8, 4, 2, 1, bias=False),\n",
    "#             nn.BatchNorm2d(64 * 8),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             # Block 5: input is (64*8) x 4 x 4\n",
    "#             nn.Conv2d(64 * 8, 64 * 16, 4, 2, 0, bias=False),\n",
    "#             nn.BatchNorm2d(64 * 16),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(64 * 16, 64 * 16, 4, 2, 0, bias=False),\n",
    "#             nn.BatchNorm2d(64 * 16),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(64 * 16, 64 * 8, 4, 2, 0, bias=False),\n",
    "#             nn.BatchNorm2d(64 * 8),\n",
    "#             nn.LeakyReLU(0.2, inplace=True),\n",
    "#             nn.Conv2d(64 * 8, 1, 2, 1, 0, bias=False),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Sigmoid()\n",
    "#             # nn.Linear(841, 256),\n",
    "#             # nn.LeakyReLU(0.2),\n",
    "#             # nn.Dropout(0.3),\n",
    "#             # nn.Linear(256, 1),\n",
    "#             # nn.Sigmoid()\n",
    "#         )\n",
    " \n",
    "#     def forward(self, input):\n",
    "#         output = self.main(input)\n",
    "#         # print(output.shape)\n",
    "#         return output\n",
    "\n",
    "Discrim = monai.networks.nets.Discriminator(\n",
    "    in_shape=(1, img_size, img_size),\n",
    "    channels=(8, 16, 32, 64, 1),\n",
    "    strides=(2, 2, 2, 2, 1),\n",
    "    num_res_units=2,\n",
    "    kernel_size=3,\n",
    "    dropout=0.4\n",
    ")\n",
    "\n",
    "    \n",
    "discriminator = Discrim.to(device)\n",
    "print('\\n##### DISCRIMINATOR #####')\n",
    "print(discriminator)\n",
    "print('######################')\n",
    "\n",
    "# loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# optimizers\n",
    "# optim_g = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optim_d = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "torchinfo.summary(Discrim, input_size=(2, 1, img_size, img_size), depth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f0340e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30ce8c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_epochs = EP\n",
    "epoch_loss_values = []\n",
    "val_interval = 1\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "epoch_val_loss_values = []\n",
    "epoch_loss_d_values = []\n",
    "epoch_loss_g_values = []\n",
    "metric_values = []\n",
    "best_loss = 1e10\n",
    "best_dsc = 0\n",
    "k=1\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"Epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss, step = 0, 0\n",
    "\n",
    "    epoch_DSC, epoch_L2, epoch_MI, epoch_ddf = 0, 0, 0, 0\n",
    "\n",
    "    epoch_loss_d, epoch_loss_g=0,0\n",
    "    \n",
    "    for fixed_train_img_, fixed_train_msk_, moving_train_img_, moving_train_msk_ in zip(fixed_train_img,\n",
    "                                                                                    fixed_train_msk, moving_train_img,\n",
    "                                                                                    moving_train_msk):    \n",
    "        step += 1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        optim_d.zero_grad()\n",
    "\n",
    "        fixed_train_img_ = fixed_train_img_.to(device)\n",
    "        fixed_train_msk_ = fixed_train_msk_.to(device)\n",
    "        moving_train_img_ = moving_train_img_.to(device)\n",
    "        moving_train_msk_ = moving_train_msk_.to(device)\n",
    "        \n",
    "        ddf_train = model(torch.cat((moving_train_img_, fixed_train_img_), dim=1))\n",
    "        \n",
    "        pred_image_train = warp_layer(moving_train_img_, ddf_train)\n",
    "        pred_mask_train = warp_layer(moving_train_msk_, ddf_train)\n",
    "\n",
    "        real_label = label_real(fixed_train_img_.size(0))\n",
    "        fake_label = label_fake(fixed_train_img_.size(0))\n",
    "\n",
    "\n",
    "        output_real = discriminator(fixed_train_img_)\n",
    "        loss_real = criterion(output_real, real_label)\n",
    "        loss_real.backward()\n",
    "\n",
    "        output_fake = discriminator(pred_image_train.detach())\n",
    "        loss_fake = criterion(output_fake, fake_label)\n",
    "        loss_fake.backward()\n",
    "\n",
    "        optim_d.step()\n",
    "\n",
    "        loss_d = (loss_real + loss_fake)/2\n",
    "\n",
    "        epoch_loss_d += loss_d.item()\n",
    "\n",
    "        output = discriminator(pred_image_train)\n",
    "        \n",
    "        loss_g = criterion(output, real_label)\n",
    "\n",
    "        imageLOSS = image_loss(pred_image_train, fixed_train_img_)\n",
    "        \n",
    "        labelDSC = label_loss(fixed_train_msk_, pred_mask_train)\n",
    "\n",
    "        # labelDSC = label_loss(make_one_hot(pred_mask_train, C=3), make_one_hot(fixed_train_msk_, C=3))\n",
    "\n",
    "        labelGlobal =  globalLoss(fixed_train_msk_, pred_mask_train)-1\n",
    "        \n",
    "        regLOSS  = regularization(ddf_train)\n",
    "\n",
    "        \n",
    "        loss = imageLOSS + regLOSS + 2*labelGlobal + 2*labelDSC + 0.001*loss_g\n",
    "    \n",
    "        # loss_g.backward(retain_graph=True)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss_g += loss_g.item()\n",
    "        epoch_DSC += labelDSC.item()\n",
    "        epoch_L2 += labelGlobal.item()\n",
    "        epoch_MI += imageLOSS.item()\n",
    "        epoch_ddf += regLOSS.item()\n",
    "\n",
    "\n",
    "        \n",
    "        dice_metric(y_pred = make_one_hot(pred_mask_train, C=3), y=make_one_hot(fixed_train_msk_, C=3))\n",
    "\n",
    "    metric = dice_metric.aggregate().item()\n",
    "    dice_metric.reset()\n",
    "    epoch_loss /= step\n",
    "\n",
    "    epoch_loss_g /=step\n",
    "    epoch_loss_d /= step\n",
    "\n",
    "    epoch_DSC /= step\n",
    "    epoch_L2 /= step\n",
    "    epoch_MI /= step\n",
    "    epoch_ddf /= step\n",
    "\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    epoch_loss_d_values.append(epoch_loss_d)\n",
    "    epoch_loss_g_values.append(epoch_loss_g)\n",
    "\n",
    "    print(f\"For epoch: {epoch + 1}, Average train loss: {epoch_loss:.5f} !\")\n",
    "    print(f\"For epoch: {epoch + 1}, Average train DSC: {metric:.5f} !\\n\")\n",
    "\n",
    "    print(f\"For epoch: {epoch + 1}, Average train DSC: {epoch_DSC:.5f} !\")\n",
    "    print(f\"For epoch: {epoch + 1}, Average train L2: {epoch_L2:.5f} !\")\n",
    "    print(f\"For epoch: {epoch + 1}, Average train MI: {epoch_MI:.5f} !\")\n",
    "    print(f\"For epoch: {epoch + 1}, Average train DDF: {epoch_ddf:.5f} !\")\n",
    "    print(f\"For epoch: {epoch + 1}, Average train D Loss: {epoch_loss_d:.5f} !\")\n",
    "    print(f\"For epoch: {epoch + 1}, Average train G Loss: {epoch_loss_g:.5f} !\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    if (epoch + 1) % val_interval == 0 or epoch == 0:\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_met = 0\n",
    "        step = 0\n",
    "        with torch.no_grad():\n",
    "            for fixed_val_img_, fixed_val_msk_, moving_val_img_, moving_val_msk_ in zip(fixed_val_img, fixed_val_msk,\n",
    "                                                                                        moving_val_img, moving_val_msk):  \n",
    "\n",
    "                fixed_val_img_ = fixed_val_img_.to(device)\n",
    "                fixed_val_msk_ = fixed_val_msk_.to(device)\n",
    "                \n",
    "                moving_val_img_ = moving_val_img_.to(device)\n",
    "                moving_val_msk_ = moving_val_msk_.to(device)\n",
    "                \n",
    "                \n",
    "                ddf_val = model(torch.cat((moving_val_img_, fixed_val_img_), dim=1))\n",
    "                \n",
    "                pred_image_val = warp_layer(moving_val_img_, ddf_val)\n",
    "                pred_mask_val = warp_layer(moving_val_msk_, ddf_val)\n",
    "\n",
    "                real_label = label_real(pred_image_val.size(0))\n",
    "        \n",
    "                output = discriminator(pred_image_val)\n",
    "        \n",
    "                loss_g = criterion(output, real_label)\n",
    "\n",
    "                imageLOSS = image_loss(pred_image_val, fixed_val_img_)\n",
    "\n",
    "                labelDSC = label_loss(fixed_val_msk_, pred_mask_val)\n",
    "\n",
    "                # labelDSC = label_loss(make_one_hot(pred_mask_val, C=3), make_one_hot(fixed_val_msk_, C=3))\n",
    "\n",
    "                labelGlobal =  globalLoss(fixed_val_msk_, pred_mask_val)-1\n",
    "\n",
    "                regLOSS  = regularization(ddf_val)\n",
    "\n",
    "\n",
    "                loss = imageLOSS + regLOSS + 2*labelGlobal + 2*labelDSC + 0.001*loss_g\n",
    "                \n",
    "                \n",
    "    \n",
    "                val_loss += loss.item()\n",
    "                step += 1\n",
    "\n",
    "                \n",
    "                dice_metric(y_pred = make_one_hot(pred_mask_val, C=3), y=make_one_hot(fixed_val_msk_, C=3))\n",
    "                \n",
    "\n",
    "            val_loss /= step\n",
    "            epoch_val_loss_values.append(val_loss)\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            metric_values.append(metric)\n",
    "            dice_metric.reset()\n",
    "            \n",
    "            if metric > best_dsc:\n",
    "                best_loss_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(),\n",
    "                           os.path.join(root_dir, fileNames+'.pth'))\n",
    "                print(f\"Valid DSC improved from {best_dsc:2.4f} to {metric:2.4f}! Best model is saving as---> {fileNames+'.pth'}\")\n",
    "                best_dsc = metric\n",
    "                \n",
    "            print(\n",
    "                f\"\\nCurrent mean dice: {metric:.4f} \"\n",
    "                f\"\\t and \\t Current val loss: {val_loss:.4f}\\n\\n\"\n",
    "                f\"Best val DSC: {best_dsc:.4f} \"\n",
    "                f\"at epoch number of {best_loss_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dc147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and save the generator and discriminator loss\n",
    "plt.figure(\"train\", (20, 4))\n",
    "plt.subplot(121)\n",
    "plt.plot(epoch_loss_values, label='Generator loss')\n",
    "plt.subplot(122)\n",
    "plt.plot(epoch_loss_d_values, label='Discriminator Loss')\n",
    "plt.plot(epoch_loss_g_values, label='Generator Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d3bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(\"train\", (20, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epoch_loss_values, label = 'training', color='k', lw=2, linestyle='-', marker = 'o')\n",
    "plt.plot(epoch_val_loss_values, label = 'val', color='b', lw=2, linestyle='-', marker = 'x')\n",
    "plt.legend(fontsize=20, loc='upper right', ncol=1)\n",
    "plt.xticks(range(0, max_epochs , 1))\n",
    "plt.ylabel('Losses', fontsize=20)\n",
    "plt.xlabel('Epochs', fontsize=20)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(metric_values, label = 'training', color='k', lw=2, linestyle='-', marker = 'o')\n",
    "plt.ylabel('DSC', fontsize=20)\n",
    "plt.xlabel('Epochs', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6766fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hausdorff (mask1, mask2):\n",
    "    mask1_class_LV = mask1.copy()\n",
    "    mask1_class_Myo = mask1.copy()\n",
    "    \n",
    "    mask1_class_LV[mask1_class_LV==1] = 0\n",
    "    mask1_class_Myo[mask1_class_Myo==2] = 0\n",
    "    \n",
    "    mask2_class_LV = mask2.copy()\n",
    "    mask2_class_Myo = mask2.copy()\n",
    "    \n",
    "    mask2_class_LV[mask2_class_LV==1] = 0\n",
    "    mask2_class_Myo[mask2_class_Myo==2] = 0\n",
    "    \n",
    "    hausdorff_Myo = (directed_hausdorff(mask1_class_Myo, mask2_class_Myo)[0]+directed_hausdorff(mask2_class_Myo, mask1_class_Myo)[0])/2\n",
    "\n",
    "    hausdorff_LV = (directed_hausdorff(mask1_class_LV, mask2_class_LV)[0]+directed_hausdorff(mask2_class_LV, mask1_class_LV)[0])/2\n",
    "    \n",
    "    return [hausdorff_Myo, hausdorff_LV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed89cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(root_dir, fileNames+'.pth')))\n",
    "model.eval()\n",
    "\n",
    "metric = monai.metrics.MSEMetric()\n",
    "\n",
    "before_MSEMetric = []\n",
    "after_MSEMetric = []\n",
    "\n",
    "before_compute_meandice = []\n",
    "after_compute_meandice = []\n",
    "\n",
    "before_compute_hausdorff_distance = []\n",
    "after_compute_hausdorff_distance = []\n",
    "                                                                         \n",
    "\n",
    "for fixed_val_img_, fixed_val_msk_, moving_val_img_, moving_val_msk_ in zip(fixed_val_img, fixed_val_msk,\n",
    "                                                                                        moving_val_img, moving_val_msk): \n",
    "    \n",
    "    fixed_val_img_ = fixed_val_img_.to(device)\n",
    "    fixed_val_msk_ = fixed_val_msk_.to(device)\n",
    "\n",
    "    moving_val_img_ = moving_val_img_.to(device)\n",
    "    moving_val_msk_ = moving_val_msk_.to(device)\n",
    "\n",
    "\n",
    "    ddf_val = model(torch.cat((moving_val_img_, fixed_val_img_), dim=1))\n",
    "\n",
    "    pred_image_val = warp_layer(moving_val_img_, ddf_val)\n",
    "    pred_mask_val = warp_layer(moving_val_msk_, ddf_val)\n",
    "    \n",
    "    \n",
    "    before_MSEMetric.extend(metric(moving_val_img_,fixed_val_img_).detach().cpu().numpy())\n",
    "    \n",
    "    after_MSEMetric.extend(metric(pred_image_val,fixed_val_img_).detach().cpu().numpy())\n",
    "    \n",
    "#     print(metric(pred_image_val,fixed_val_img_).detach().cpu().numpy())\n",
    "\n",
    "    before_compute_hausdorff_distance.extend((compute_hausdorff_distance(y_pred = make_one_hot(moving_val_msk_, C=3), y=make_one_hot(fixed_val_msk_, C=3), directed=True)).detach().cpu().numpy())\n",
    "    after_compute_hausdorff_distance.extend((compute_hausdorff_distance(y_pred = make_one_hot(pred_mask_val, C=3), y=make_one_hot(fixed_val_msk_, C=3), directed=True)).detach().cpu().numpy()) \n",
    "    \n",
    "    \n",
    "    before_compute_meandice.extend((compute_meandice(y_pred = make_one_hot(moving_val_msk_, C=3), y=make_one_hot(fixed_val_msk_, C=3))).detach().cpu().numpy())\n",
    "    after_compute_meandice.extend((compute_meandice(y_pred = make_one_hot(pred_mask_val, C=3), y=make_one_hot(fixed_val_msk_, C=3))).detach().cpu().numpy()) \n",
    "    \n",
    "    \n",
    "#     break\n",
    "\n",
    "print(np.array(before_MSEMetric).shape)\n",
    "print(np.array(after_MSEMetric).shape)\n",
    "\n",
    "print(np.array(before_compute_meandice).shape)\n",
    "print(np.array(after_compute_meandice).shape)\n",
    "\n",
    "print()\n",
    "\n",
    "print(f'MSEMetric W/O registration {np.mean(np.array(before_MSEMetric))}')\n",
    "print(f'MSEMetric W/ registration = {np.mean(np.array(after_MSEMetric))}')\n",
    "\n",
    "print(f'Mean dice W/O registration = {np.mean(np.array(before_compute_meandice), axis=0)}')\n",
    "print(f'Mean dice W/ registration = {np.mean(np.array(after_compute_meandice), axis=0)}')\n",
    "\n",
    "print(f'Hausdorff_distance W/O registration = {np.mean(np.array(before_compute_hausdorff_distance), axis=0)}')\n",
    "print(f'Hausdorff_distance W/ registration = {np.mean(np.array(after_compute_hausdorff_distance), axis=0)}')\n",
    "\n",
    "print()\n",
    "\n",
    "print('----------------For Report Metric +/- Std-----------------------')\n",
    "print(f'Mean dice W/O registration = {np.mean(np.mean(np.array(before_compute_meandice), axis=0))} + {np.mean(np.std(np.array(before_compute_meandice), axis=0))}')\n",
    "print(f'Mean dice W/ registration = {np.mean(np.mean(np.array(after_compute_meandice), axis=0))} + {np.mean(np.std(np.array(after_compute_meandice), axis=0))}')\n",
    "\n",
    "print(f'Hausdorff_distance W/O registration = {np.mean(np.mean(np.array(before_compute_hausdorff_distance), axis=0))} + {np.mean(np.std(np.array(before_compute_hausdorff_distance), axis=0))}')\n",
    "print(f'Hausdorff_distance W/ registration = {np.mean(np.mean(np.array(after_compute_hausdorff_distance), axis=0))} + {np.mean(np.std(np.array(after_compute_hausdorff_distance), axis=0))}')\n",
    "\n",
    "df = ({\n",
    "     'before_compute_hausdorff_distance':np.mean(np.array(before_compute_hausdorff_distance), axis=1),\n",
    "     'after_compute_hausdorff_distance'   : np.mean(np.array(after_compute_hausdorff_distance), axis=1),\n",
    "     'before_compute_meandice':np.mean(np.array(before_compute_meandice), axis=1),\n",
    "     'after_compute_meandice':np.mean(np.array(after_compute_meandice), axis=1),\n",
    "     'before_MSEMetric': np.mean(np.array(before_MSEMetric), axis=1),\n",
    "     'after_MSEMetric':np.mean(np.array(after_MSEMetric), axis=1)\n",
    "})\n",
    "\n",
    "pd.DataFrame(df).to_csv(fileNames+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfc42c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(root_dir, fileNames+'.pth')))\n",
    "model.eval()\n",
    "                                          \n",
    "\n",
    "for fixed_val_img_, fixed_val_msk_, moving_val_img_, moving_val_msk_ in zip(fixed_val_img, fixed_val_msk,\n",
    "                                                                                        moving_val_img, moving_val_msk): \n",
    "    \n",
    "    fixed_val_img_ = fixed_val_img_.to(device)\n",
    "    fixed_val_msk_ = fixed_val_msk_.to(device)\n",
    "\n",
    "    moving_val_img_ = moving_val_img_.to(device)\n",
    "    moving_val_msk_ = moving_val_msk_.to(device)\n",
    "\n",
    "\n",
    "    ddf_val = model(torch.cat((moving_val_img_, fixed_val_img_), dim=1))\n",
    "\n",
    "    pred_image_val = warp_layer(moving_val_img_, ddf_val)\n",
    "    pred_mask_val = warp_layer(moving_val_msk_, ddf_val)\n",
    "    \n",
    "    \n",
    "    break\n",
    "\n",
    "fixed_val_img_ = fixed_val_img_.detach().cpu().numpy()[:, 0]\n",
    "fixed_val_msk_ = fixed_val_msk_.detach().cpu().numpy()[:, 0]\n",
    "\n",
    "moving_val_img_ = moving_val_img_.detach().cpu().numpy()[:, 0]\n",
    "moving_val_msk_ = moving_val_msk_.detach().cpu().numpy()[:, 0]\n",
    "\n",
    "pred_image_val = pred_image_val.detach().cpu().numpy()[:, 0]\n",
    "pred_mask_val = pred_mask_val.detach().cpu().numpy()[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colored (pred_img, true_img): \n",
    "    bitwise_and = cv2.bitwise_and(pred_img, true_img)\n",
    "    \n",
    "    TP = np.stack((np.zeros_like(bitwise_and), bitwise_and, np.zeros_like(bitwise_and)), axis=-1)\n",
    "    \n",
    "    FN = np.stack((true_img-bitwise_and,\n",
    "                   true_img-bitwise_and,\n",
    "                   np.zeros_like(true_img-bitwise_and)), axis=-1)\n",
    "    \n",
    "    FP = np.stack((pred_img-bitwise_and,\n",
    "                   pred_img-bitwise_and,\n",
    "                  np.zeros_like(pred_img-bitwise_and)), axis=-1)\n",
    "    \n",
    "    return (255*(TP+FN+FP)).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb5141",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "batch_size = testBatch\n",
    "plt.subplots(batch_size, 7, figsize=(12, 15))\n",
    "\n",
    "for b in range(batch_size):\n",
    "    # moving image\n",
    "    plt.subplot(batch_size, 7, b * 7 + 1)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"moving img\")\n",
    "    plt.imshow(moving_val_img_[b], cmap=\"gray\")\n",
    "    \n",
    "    # moving label\n",
    "    plt.subplot(batch_size, 7, b * 7 + 2)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"moving lab\")\n",
    "    plt.imshow(moving_val_msk_[b], cmap=\"gray\")\n",
    "    \n",
    "    \n",
    "    # fixed image\n",
    "    plt.subplot(batch_size, 7, b * 7 + 3)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"fixed img\")\n",
    "    plt.imshow(fixed_val_img_[b], cmap=\"gray\")\n",
    "    \n",
    "    # fixed label\n",
    "    plt.subplot(batch_size, 7, b * 7 + 4)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"fixed lab\")\n",
    "    plt.imshow(fixed_val_msk_[b], cmap=\"gray\")\n",
    "    \n",
    "    \n",
    "    # warped moving\n",
    "    plt.subplot(batch_size, 7, b * 7 + 5)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Pred Img\")\n",
    "    plt.imshow(pred_image_val[b], cmap=\"gray\")\n",
    "\n",
    "\n",
    "    # warped moving\n",
    "    plt.subplot(batch_size, 7, b * 7 + 6)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Before Reg\")\n",
    "    plt.imshow(colored(moving_val_msk_[b], fixed_val_msk_[b]))\n",
    "    \n",
    "    \n",
    "    # warped moving\n",
    "    plt.subplot(batch_size, 7, b * 7 + 7)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"After Reg\")\n",
    "    plt.imshow(colored(pred_mask_val[b], fixed_val_msk_[b]))\n",
    "    \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6a13f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28303b33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "886930dad8d4457679a0ca572c30287744b0c7f7c87d123d0e54902f7e45ac8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
